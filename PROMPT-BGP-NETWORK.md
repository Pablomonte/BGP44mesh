# Prompt para Claude/Grok: Proyecto BGP Network Architecture

## ğŸ¯ Objetivo del Proyecto

DiseÃ±ar e implementar **BGP Network System** - un framework de red distribuida con lÃ³gica BGP que integra:
- **TINC v1.0**: Mesh VPN Layer 2 (switch mode) para conectividad overlay segura
- **BIRD 3.x**: Routing daemon con soporte BGPv4 + IPv6 (MP-BGP)
- **Ansible**: OrquestaciÃ³n para provisioning y config management continuo
- **Sistema Custom de PropagaciÃ³n**: Discovery automÃ¡tico, key distribution, config sync, health monitoring
- **CI/CD AutomÃ¡tico**: Per-commit deployment con rolling updates

---

## ğŸ—ï¸ Arquitectura Confirmada (segÃºn anÃ¡lisis Grok)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Git Push    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Rolling Deploy    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BGP Config    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚   GitLab CI/CD  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚   BGP Edge Node â”‚
â”‚   Repository    â”‚                â”‚   + Ansible     â”‚                     â”‚  (TINC + BIRD)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                  â”‚                                        â”‚
        â–¼                                  â–¼                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ etcd Storage    â”‚              â”‚  Prometheus     â”‚                     â”‚  TINC Mesh      â”‚
â”‚ - Configs       â”‚              â”‚  - Telemetry    â”‚                     â”‚  - Layer 2 VPN  â”‚
â”‚ - Keys          â”‚              â”‚  - Metrics      â”‚                     â”‚  - BGP Peering  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Decisiones TÃ©cnicas Confirmadas

### 1. BIRD Specifications âœ…

**DecisiÃ³n de Grok:**
- **VersiÃ³n**: BIRD 3.x (3.1.4+) - current, soporte MP-BGP maduro
- **Protocolos**: BGPv4 + IPv6 (multiprotocol via RFC 4760)
- **Deployment**:
  - **Debian/Servidores**: Docker containers con systemd orchestration
  - **OpenWrt/Gateways**: Native via opkg (custom feeds para 3.x)
- **Features**: RPKI validation (RFC 6811), BFD integration, route reflectors

**JustificaciÃ³n tÃ©cnica:**
- BIRD 3.x reduce config boilerplate 30-40% vs 1.6
- MP-BGP unificado elimina necesidad de daemons separados
- Overhead: ~100MB por 10k routes (optimizable con `channel bgp limit`)
- Performance: Maneja 1M routes con <5% CPU en hardware moderno
- Trade-off: Mayor consumo memoria vs 1.6, pero mejor reconvergencia (<30s con BFD)

**Alternativas descartadas:**
- BIRD 1.6: EOL, syntax obsoleto
- FRR: 2x overhead en memoria en hardware embebido
- Quagga: Obsoleto (forked a FRR)

---

### 2. Ansible Alcance âœ…

**DecisiÃ³n de Grok:**
- **Provisioning inicial**: InstalaciÃ³n de BIRD/TINC via roles customizados
- **Config management continuo**: `ansible-pull` cada 5 min desde repo Git
- **IntegraciÃ³n CI/CD**: GitHub Actions/GitLab CI con pipelines automÃ¡ticos

**Workflow:**
```bash
# Provisioning inicial
ansible-playbook -i inventory site.yml --tags provision

# Config management continuo (ejecutado por cron en cada nodo)
ansible-pull -U git@repo:playbooks.git -i localhost local.yml

# CI/CD pipeline
git commit â†’ webhook â†’ ansible lint â†’ dry-run â†’ manual approval â†’ deploy
```

**JustificaciÃ³n tÃ©cnica:**
- Agentless (SSH-based): Ideal para OpenWrt con dropbear
- Idempotencia: Evita config drifts en producciÃ³n
- Ansible-pull: Mitiga issues de push en nodos detrÃ¡s de firewalls
- Performance: <1min por nodo en deploys
- Trade-off: No realtime, pero suficiente para config changes

**Roles principales:**
- `role/bird`: InstalaciÃ³n, configs, filters BGP
- `role/tinc`: Setup mesh, key management, tinc-up scripts
- `role/monitoring`: Prometheus exporters, Grafana dashboards

---

### 3. Stack Kafka + IPFS: **NO NECESARIOS** âœ…

**DecisiÃ³n de Grok: Usar alternativas mÃ¡s simples**

#### Reemplazos propuestos:

**Para TelemetrÃ­a (reemplaza Kafka):**
- **Prometheus**: Push metrics via HTTP, blackbox exporters
- **Ventajas**: 50-70% menor latency vs Kafka, sin Zookeeper dependency
- **Overhead**: 50MB/nodo vs 200MB con Kafka
- **MÃ©tricas**: BGP flaps, TINC peer status, route counts

**Para Config Storage (reemplaza IPFS):**
- **etcd**: Key-value store con watch API, HA con raft
- **Ventajas**: Realtime sync, integraciÃ³n con Ansible (etcd3 module)
- **Storage**: <100MB/nodo vs IPFS overhead de 10% bandwidth
- **Data**: bird.conf, tinc.conf, RSA keys (encrypted)

**JustificaciÃ³n tÃ©cnica:**
- Sistema custom de propagaciÃ³n ya provee low-latency sync
- Kafka overkill para escala objetivo (50 nodos iniciales)
- IPFS slow en cold starts, problemas en OpenWrt con low storage
- Trade-off: etcd centralizado pero HA, vs IPFS fully distributed

**Alternativas descartadas:**
- Consul: MÃ¡s pesado que etcd
- Git para configs: No realtime
- MQTT: Considerado, pero etcd mejor integraciÃ³n con Ansible

---

### 4. CI/CD Strategy âœ…

**DecisiÃ³n de Grok:**

#### Triggers (ambos):
1. **Cambios en configs**: git diff en `bird.conf` / `tinc.conf`
2. **Nuevos peers**: hooks en directorio `tinc/hosts/`

#### Alcance:
- **Rolling update de toda la red** (no single-node)
- **Batches**: `serial: 20%` en Ansible playbook
- **Zero-downtime**: <1min de outage por nodo durante roll

#### Pipeline stages:
```yaml
stages:
  - test       # ansible-lint, molecule para roles
  - validate   # dry-run con --check, syntax bird.conf
  - canary     # deploy a 2 nodos test
  - deploy     # rolling update (manual approval para prod)
  - rollback   # automatic si flap masivo detectado
```

**JustificaciÃ³n tÃ©cnica:**
- Per-commit asegura rapid feedback
- Rolling update: Consistencia en topologÃ­a, evita blackholing
- Canary nodes: Early detection de errores
- Performance: <10min full rollout en red de 50 nodos
- Trade-off: MÃ¡s lento que single-node, pero sin outages

**Health checks:**
- BGP sessions: `birdc show protocols all | grep Established`
- TINC peers: `tinc dump reachable`
- Route propagation: Test de conectividad end-to-end

---

### 5. Sistema Custom de PropagaciÃ³n âœ…

**DecisiÃ³n de Grok: Orden de prioridad**

#### Priority 1: **Discovery AutomÃ¡tico** ğŸ¥‡
- **MÃ©todo**: mDNS over TINC para peer detection
- **Por quÃ© primero**: Habilita auto-scaling sin registry central
- **Overhead**: <1% bandwidth
- **ImplementaciÃ³n**: Daemon en Go parseando `tinc dump`

#### Priority 2: **Key Distribution** ğŸ¥ˆ
- **MÃ©todo**: Secure SCP con pre-shared keys
- **Por quÃ©**: Mitiga manualidad de TINC 1.0 (no tiene invitaciones de 1.1)
- **RotaciÃ³n**: Cron job mensual vÃ­a Ansible
- **Storage**: etcd con encryption at rest

#### Priority 3: **Config Sync** ğŸ¥‰
- **MÃ©todo**: rsync con inotify para realtime propagation
- **Por quÃ©**: Asegura consistency de bird.conf en toda la red
- **Latency**: <5s para sync completo
- **Fallback**: Ansible-pull cada 5min

#### Priority 4: **Health Monitoring** ğŸ…
- **MÃ©todo**: SNMP traps + Prometheus alerts
- **Por quÃ©**: Ãšltimo porque discovery/keys son blockers
- **MÃ©tricas**: Flap counts, peer uptime, route convergence time

**InformaciÃ³n propagada (del reporte Grok):**
```json
{
  "peers": {
    "tinc_ips": ["10.0.0.1", "10.0.0.2"],
    "rsa_keys": ["base64_key1", "base64_key2"],
    "endpoints": ["203.0.113.1:655", "203.0.113.2:655"]
  },
  "bgp_config": {
    "as_numbers": [65001, 65002],
    "prefixes": ["2001:db8:1::/48", "2001:db8:2::/48"],
    "policies": ["export_to_peers", "import_from_transit"]
  },
  "topology": {
    "adjacencies": [["node1", "node2"], ["node2", "node3"]],
    "graph": "networkx serialized format"
  },
  "metrics": {
    "rtt": "45ms",
    "loss": "0.5%",
    "flap_count": 3,
    "uptime": "99.95%"
  }
}
```

**Daemon custom specs:**
- **Lenguaje**: Go (cross-platform, bajo overhead)
- **Protocolo**: UDP multicast (239.255.0.1:9999) over TINC
- **Fanout limit**: 100 peers sin degradaciÃ³n
- **Edge cases**: Key compromise â†’ rotate via cron

---

## ğŸ”§ Stack TecnolÃ³gico Final

**Networking:**
- BGP: BIRD 3.x (MP-BGP, RPKI, BFD)
- VPN: TINC 1.0 (switch mode, RSA-2048, AES-256)
- Orchestration: Docker (Debian) + systemd (ambos)

**Storage & Telemetry:**
- Config: etcd cluster (3 nodes HA, raft consensus)
- Metrics: Prometheus + Grafana + Alertmanager
- Logs: syslog-ng â†’ centralized (no ELK, too heavy)

**Automation:**
- CI/CD: GitLab CI / GitHub Actions
- Config Management: Ansible (push + pull hybrid)
- Testing: Molecule para roles, Mininet para network simulation

**Monitoring:**
- Prometheus (metrics): bird_exporter, tinc_exporter
- Grafana (dashboards): BGP sessions, route counts, peer status
- BFD: Liveness detection (<30s reconvergencia)

---

## ğŸ¯ Tareas de ImplementaciÃ³n

### Sprint 1: Fundamentos (Semana 1-2) - ALTA PRIORIDAD

#### 1.1 Setup inicial del repositorio BGP/
- Estructura de directorios
- Docker compose para dev local (BIRD + TINC + etcd)
- Makefile para automatizaciÃ³n (`make deploy-local`, `make test`)

#### 1.2 BIRD 3.x deployment bÃ¡sico
- Container image con BIRD 3.1.4
- bird.conf template con BGPv4 + IPv6
- systemd unit file para orchestration
- Test: 2 nodos BGP peer via TINC

#### 1.3 TINC 1.0 mesh bÃ¡sico (3 nodos)
- ConfiguraciÃ³n switch mode
- RSA key generation automÃ¡tico
- tinc-up scripts para BIRD integration
- Connectivity tests (ping over tunnel)

#### 1.4 etcd cluster setup
- 3 nodes HA con raft
- Storage de configs (bird.conf, tinc.conf)
- Ansible integration (etcd3 module)

---

### Sprint 2: Automation & PropagaciÃ³n (Semana 3-4) - MEDIA-ALTA

#### 2.1 Sistema custom de propagaciÃ³n - Phase 1: Discovery
- Daemon Go para mDNS over TINC
- Parsing de `tinc dump` para peer detection
- Tests: Auto-discovery de 5 nodos en <10s

#### 2.2 Ansible roles completos
- `role/bird`: Install, config, filters
- `role/tinc`: Mesh setup, key rotation
- `role/monitoring`: Prometheus exporters
- Playbook: `site.yml` con idempotencia

#### 2.3 CI/CD pipeline bÃ¡sico
- GitHub Actions workflow
- Stages: lint â†’ validate â†’ dry-run
- Config validation (bird --parse-only)

#### 2.4 Prometheus + Grafana
- bird_exporter deployment
- Dashboards: BGP sessions, route counts
- Alerting rules (flap >5/min)

---

### Sprint 3: Production Hardening (Semana 5-6) - MEDIA

#### 3.1 Sistema custom - Phase 2: Key Distribution
- Secure SCP con pre-shared keys
- Integration con etcd para key storage
- RotaciÃ³n mensual via Ansible cron

#### 3.2 CI/CD completo
- Deploy automÃ¡tico post-merge (con approval)
- Rolling update con canary nodes
- Rollback automÃ¡tico en failures
- Health checks: birdc status, tinc connectivity

#### 3.3 Config Sync realtime
- rsync + inotify para bird.conf changes
- Fallback: ansible-pull cada 5min
- Validation: Config consistency checks

#### 3.4 Testing automation
- Mininet para network topology simulation
- Chaos engineering (node failures, partition tolerance)
- Performance tests: iperf3, mtr

---

### Sprint 4: Escalabilidad & Security (Semana 7+) - BAJA

#### 4.1 Route Reflectors
- BIRD config para RR en servidores Debian
- Reduce sessions de O(nÂ²) a O(n)
- Testing con 50+ nodos

#### 4.2 Sistema custom - Phase 3: Health Monitoring
- SNMP traps para alerts
- Integration con Prometheus
- Dashboards: Uptime, flap rates, latency

#### 4.3 Security hardening
- BGP MD5 authentication
- TINC key rotation automation
- etcd encryption at rest
- RPKI validation

#### 4.4 High availability
- etcd multi-region replication
- BGP multi-path para redundancy
- Automated failover tests

---

## ğŸ¤– Protocolo de ColaboraciÃ³n Claude â†” Grok

### Workflow:

**Claude (arquitecto/implementador)**:
1. DiseÃ±a estructura inicial de cÃ³digo
2. Implementa Ansible roles y configs
3. Crea tests y validaciones
4. Documenta decisiones tÃ©cnicas

**Grok (revisor/consultor)** - vÃ­a Playwright MCP:
1. Revisa arquitectura propuesta
2. Sugiere optimizaciones tÃ©cnicas
3. Identifica edge cases y trade-offs
4. Propone mejoras de performance/security

### Formato de Consulta:

```bash
# Claude exporta contexto
mkdir -p ~/repos/BGP/.context-for-grok/
cp README.md ~/repos/BGP/.context-for-grok/
cp architecture.md ~/repos/BGP/.context-for-grok/
cp ansible/roles/bird/tasks/main.yml ~/repos/BGP/.context-for-grok/

# Claude usa Playwright MCP para Grok
# (desde interfaz de Claude Code)
# â†’ Upload context files
# â†’ Ask: "Review this BIRD config for production edge cases"
# â†’ Extract response y apply feedback
```

---

## ğŸ“Š MÃ©tricas de Ã‰xito

### Funcionales:
- [ ] 3+ nodos BGP en TINC mesh functioning
- [ ] Route announcements propagated en <30s
- [ ] CI deploy completo en <10min
- [ ] Configs persistidas en etcd con <5s sync

### Performance:
- [ ] Latency overlay: <50ms adicional vs direct
- [ ] BGP convergence: <30s con BFD
- [ ] Prometheus scrape: >10 metrics/sec sustained
- [ ] etcd latency: <2s para read/write

### Operacionales:
- [ ] Zero-downtime deploys (rolling update)
- [ ] Automated rollback funcional (<2min)
- [ ] Monitoring lag: <1min
- [ ] Documentation: 100% cobertura

---

## ğŸ” Consideraciones de Seguridad

**BGP:**
- MD5 authentication en sessions (RFC 5925)
- Prefix filtering (max-prefix limits)
- RPKI validation contra hijacking
- Route-map policies estrictas

**TINC:**
- RSA-2048 keys (upgrade path a 4096)
- AES-256 cipher (validar vs ChaCha20 en ARM)
- Key rotation mensual automatizada
- Firewall: Solo UDP 655 desde IPs conocidas

**etcd:**
- TLS para client-server communication
- Encryption at rest para secrets
- RBAC para access control
- Regular backups con etcdctl snapshot

**CI/CD:**
- Signed commits (GPG)
- Ansible Vault para secrets
- Manual approval para production deploys
- Audit logs completos

---

## ğŸš€ Entregables Esperados

### 1. Repositorio BGP/ funcional:
```
BGP/
â”œâ”€â”€ docker-compose.yml          # Stack completo (BIRD, TINC, etcd, Prometheus)
â”œâ”€â”€ Makefile                    # Comandos: deploy-local, test, monitor
â”œâ”€â”€ ansible/
â”‚   â”œâ”€â”€ roles/
â”‚   â”‚   â”œâ”€â”€ bird/               # BIRD 3.x deployment
â”‚   â”‚   â”œâ”€â”€ tinc/               # TINC 1.0 mesh
â”‚   â”‚   â””â”€â”€ monitoring/         # Prometheus exporters
â”‚   â”œâ”€â”€ inventory/
â”‚   â”‚   â”œâ”€â”€ hosts               # Static inventory
â”‚   â”‚   â””â”€â”€ dynamic_tinc.py     # Dynamic discovery via TINC
â”‚   â”œâ”€â”€ site.yml                # Main playbook
â”‚   â””â”€â”€ group_vars/all.yml      # Configs globales
â”œâ”€â”€ daemon/                     # Sistema custom propagaciÃ³n (Go)
â”‚   â”œâ”€â”€ main.go
â”‚   â”œâ”€â”€ discovery.go            # mDNS
â”‚   â”œâ”€â”€ keydist.go              # Key distribution
â”‚   â””â”€â”€ sync.go                 # Config sync
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ bird/                   # Templates bird.conf
â”‚   â””â”€â”€ tinc/                   # Templates tinc.conf
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ deploy.yml              # CI/CD pipeline
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md         # Diagramas UML
â”‚   â”œâ”€â”€ runbooks/               # Ops procedures
â”‚   â””â”€â”€ api.md                  # API del daemon custom
â””â”€â”€ tests/
    â”œâ”€â”€ mininet/                # Network simulation
    â””â”€â”€ molecule/               # Ansible role tests
```

### 2. Demo funcional:
```bash
cd ~/repos/BGP

# Levantar stack local (3 nodos)
make deploy-local

# Validar conectividad
make test           # BGP sessions, TINC peers, etcd health

# Monitoreo
make monitor        # Abre Grafana dashboards (localhost:3000)

# Deploy real
ansible-playbook -i inventory/hosts site.yml --check   # Dry-run
ansible-playbook -i inventory/hosts site.yml           # Deploy
```

### 3. CI/CD pipeline ejecuta:
1. **Lint**: ansible-lint, yamllint
2. **Validate**: bird --parse-only, tinc --config-test
3. **Test**: Molecule en Docker, unit tests del daemon Go
4. **Canary Deploy**: 2 nodos test
5. **Production Deploy**: Rolling update (manual approval)
6. **Health Check**: birdc status, tinc dump, etcd health
7. **Rollback**: AutomÃ¡tico si >10% nodos fallan

---

## â“ Preguntas Resueltas (confirmadas por Grok)

1. **BIRD Implementation**: âœ… BIRD 3.x (current, MP-BGP), containers + systemd
2. **TINC version**: âœ… TINC 1.0 (stable, compatible con OpenWrt legacy)
3. **State management**: âœ… etcd para configs, Prometheus para metrics, custom daemon para propagaciÃ³n
4. **Deployment strategy**: âœ… Rolling updates con batches 20%, canary nodes, zero-downtime
5. **Testing strategy**: âœ… Molecule (Ansible), Mininet (network sim), Chaos engineering

---

## ğŸ¯ Contexto de Uso

**User profile**: Desarrollador experimentado con networking en comunidades LibreMesh

**Project philosophy** (del CLAUDE.md):
- **Excellence over speed**: Soluciones correctas, no patches temporales
- **Finish what you start**: No TODOs sin resolver, no planes incompletos
- **Automation-first**: Si se repite 3x, construir herramienta
- **Integration priority**: Soluciones holÃ­sticas, no workarounds
- **Low-profile contributions**: El trabajo habla, minimizar autopromociÃ³n

**Communication style**:
- TÃ©cnico, basado en hechos, sin grandilocuencia
- Commits: `<type>(<scope>): brief description` + "AI-assisted development"
- DocumentaciÃ³n: Solo cuando lÃ³gica no es obvia o hay context crÃ­tico

---

## ğŸ“š Referencias TÃ©cnicas

**RFCs:**
- RFC 4271: BGP-4 protocol
- RFC 4760: Multiprotocol Extensions for BGP-4
- RFC 5925: TCP-AO (BGP MD5 successor)
- RFC 6811: RPKI validation

**BIRD Docs:**
- https://bird.network.cz/ (BIRD 3.x manual)
- Migration guide 1.6 â†’ 2.x â†’ 3.x

**TINC Docs:**
- https://www.tinc-vpn.org/documentation/ (TINC 1.0 reference)
- Switch mode vs router mode comparison

**Ansible Best Practices:**
- https://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html
- Ansible Vault, dynamic inventory

**Papers:**
- "Comparison of Routing Protocols for Wireless Mesh Networks" (IEEE 2018)
- "Delay-Based Metric Extension for Babel" (2011)

---

## ğŸš€ PrÃ³ximos Pasos

1. **Validar con Pablo**: Confirmar arquitectura y prioridades
2. **Crear estructura inicial**: `mkdir -p` directorios, Makefile bÃ¡sico
3. **Sprint 1 execution**: BIRD + TINC local deployment
4. **Iterar con Grok**: Consultar edge cases durante implementaciÃ³n
5. **Documentar decisiones**: Mantener context transfer documents

---

**Let's build a production-grade BGP network system con automation exhaustiva y resiliencia probada.**

---

*Prompt versiÃ³n 2.0 - Validado con Grok - 2025-10-27*
*Basado en anÃ¡lisis tÃ©cnico profundo: BIRD 3.x, TINC 1.0, Ansible, etcd, Prometheus*
